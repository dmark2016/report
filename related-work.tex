\section{Related Work}
\label{sec:related-work}
%The related work section puts your paper into a research
%context. It mentions other research with similar goals or
%schemes and compares them to your work, highlighting the
%commonalities and differences. It also shows whether you have
%an overview of the research area.

Reducing the memory access time is an important issue in computer
design.  Memory prefetching is a technique to reduce memory access
times, and an significant amount of research have gone into memory
prefetchers.

In their paper on strided and sequential prefetching, \textit{Stenstrom
et al} \cite{bib:stride} find that sequential prefetching in some
cases performs better than strided prefetching. They argue that a
significant amount of the strides are shorter than the block size. In
testing our RPT implementation, we find that using 8 bits to store
strides yields speedups of $1.00\pm0.01$ for all prefetching
degrees. Changing the implementation to use 16 bits increases
prefetcher performance with speedups of $1.07\pm0.01$. In other words,
the benchmarks we test with sometimes access memory in strides greater
than block size.

In \cite{bib:jahre} Jahre describes the RPT prefetching algorithm and that RPT
is limited to constant strides.  In our experience RPT yields the best results
when the table is updated each memory access as opposed to only on cache
misses.

\textit{Smith et al} \cite{bib:ghb} describes how GHB is more space efficient
in terms of the prefetcher history table sizes.

%There is a significant difference between CPU and memory speed.
%In recent years, it has become increasingly important to speed up memory access to ensure that the CPU is not spending much of its time idle, waiting for data.
%Prefetching is one technique used to reduce memory access time.

%Several prefetcher techniques have been researched, in order to increase memory performance.
%Well known algorithms are: sequential, stride directed \ref{bib:stride}, reference prediction table \ref{bib:jahre} and delta correlation \ref{bib:ghb}.

%A sequential prefetcher uses the principle of spatial locality.
%If one memory block is accessed, the next memory block is most likely to be used.
%However not all memory acceses are sequential,
%and an improvment to sequental prefetcher is a stride direct prefetcher.
%If a program traverses a multiple dimensional array,
%each dimension may be placed in different places in memory,
%but with a constant stride.
%By storing the memory difference the next memory stride can be prefeched.
%A futher improvement is reference table prefetcher,
%which also contains a state.
%Each time a stride is used the state is recalculated to recieve better predicions.
%Lastly the global history buffer prefetcher utilizes a FIFO queue and an index table.
%The index table contains the PC value and a pointer to the FIFO queue,
%and the FIFO queue contains the global miss address.

%To achieve best results GHB is used together with delta correlation or stride prefeching.
%This hybrid algorithm is described in greather depth in \textit{Data Cacheprefetching Using a Global History Buffer} \ref{bib:ghb}.
